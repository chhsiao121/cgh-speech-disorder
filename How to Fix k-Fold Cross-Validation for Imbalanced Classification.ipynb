{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class=0 : 990/1000 (99.0%)\n",
      "> Class=1 : 10/1000 (1.0%)\n"
     ]
    }
   ],
   "source": [
    "from numpy import unique\n",
    "from sklearn.datasets import make_classification\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[\n",
    "                           0.99, 0.01], flip_y=0, random_state=1)\n",
    "# summarize dataset\n",
    "classes = unique(y)\n",
    "total = len(y)\n",
    "for c in classes:\n",
    "\tn_examples = len(y[y == c])\n",
    "\tpercent = n_examples / total * 100\n",
    "\tprint('> Class=%d : %d/%d (%.1f%%)' % (c, n_examples, total, percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=791, 1=9, Test: 0=199, 1=1\n",
      ">Train: 0=793, 1=7, Test: 0=197, 1=3\n",
      ">Train: 0=794, 1=6, Test: 0=196, 1=4\n",
      ">Train: 0=790, 1=10, Test: 0=200, 1=0\n",
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n"
     ]
    }
   ],
   "source": [
    "# example of k-fold cross-validation with an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[\n",
    "                           0.99, 0.01], flip_y=0, random_state=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "\t# select rows\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\t# summarize train and test composition\n",
    "\ttrain_0, train_1 = len(train_y[train_y == 0]), len(train_y[train_y == 1])\n",
    "\ttest_0, test_1 = len(test_y[test_y == 0]), len(test_y[test_y == 1])\n",
    "\tprint('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' %\n",
    "\t      (train_0, train_1, test_0, test_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Cross-Validation for Imbalanced Classification\n",
    "The solution is to not split the data randomly when using k-fold cross-validation or a train-test split.\n",
    "\n",
    "Specifically, we can split a dataset randomly, although in such a way that maintains the same class distribution in each subset. This is called stratification or stratified sampling and the target variable (y), the class, is used to control the sampling process.\n",
    "\n",
    "For example, we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called stratified k-fold cross-validation and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.\n",
    "\n",
    "… it is common, in the case of class imbalances in particular, to use stratified 10-fold cross-validation, which ensures that the proportion of positive to negative examples found in the original distribution is respected in all the folds. — Page 205, Imbalanced Learning: Foundations, Algorithms, and Applications, 2013.\n",
    "\n",
    "We can make this concrete with an example.\n",
    "\n",
    "We can stratify the splits using the StratifiedKFold class that supports stratified k-fold cross-validation as its name suggests.\n",
    "\n",
    "Below is the same dataset and the same example with the stratified version of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n",
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n",
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n",
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n",
      ">Train: 0=792, 1=8, Test: 0=198, 1=2\n"
     ]
    }
   ],
   "source": [
    "# example of stratified k-fold cross-validation with an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[\n",
    "                           0.99, 0.01], flip_y=0, random_state=1)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_ix, test_ix in kfold.split(X, y):\n",
    "\t# select rows\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\t# summarize train and test composition\n",
    "\ttrain_0, train_1 = len(train_y[train_y == 0]), len(train_y[train_y == 1])\n",
    "\ttest_0, test_1 = len(test_y[test_y == 0]), len(test_y[test_y == 1])\n",
    "\tprint('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' %\n",
    "\t      (train_0, train_1, test_0, test_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=495, 1=5, Test: 0=495, 1=5\n"
     ]
    }
   ],
   "source": [
    "# example of stratified train/test split with an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[\n",
    "                           0.99, 0.01], flip_y=0, random_state=1)\n",
    "# split into train/test sets with same class ratio\n",
    "trainX, testX, trainy, testy = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# summarize\n",
    "train_0, train_1 = len(trainy[trainy == 0]), len(trainy[trainy == 1])\n",
    "test_0, test_1 = len(testy[testy == 0]), len(testy[testy == 1])\n",
    "print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' %\n",
    "      (train_0, train_1, test_0, test_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d20f1892c47f860c0f70ddee32a3691a362d56c60fa308568bd0272f56672cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
